{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"notify_time":"30","varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"jigsaw-tpu-xlm-roberta.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"edab0aabc99c493aae14171a5eabb764":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_422e749140fe49f4a8f40bf4f32a4f7a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_022b6e37c2924ae293e8926159e9f20b","IPY_MODEL_d1161f2d91914d5ea5f52f96abd1ce15"]}},"422e749140fe49f4a8f40bf4f32a4f7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"022b6e37c2924ae293e8926159e9f20b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aba4ad62a7894eaaa2d9b576077f5ab6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ee6c2b6347b463fb19f595b012dc5d8"}},"d1161f2d91914d5ea5f52f96abd1ce15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e306762228d4c2f931afc7d621ee368","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 1.89kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64e1b4a8a1fc4e7ca5ec84f76daaa70b"}},"aba4ad62a7894eaaa2d9b576077f5ab6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ee6c2b6347b463fb19f595b012dc5d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e306762228d4c2f931afc7d621ee368":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64e1b4a8a1fc4e7ca5ec84f76daaa70b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2aaf7773e0a84ce6ab12e8828e826838":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8e8511e4cdf947fab9e0882385d43324","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_044dfd985840441f9f05bdfb34caba72","IPY_MODEL_340a4815fb774e9681e4f2ac809f00b1"]}},"8e8511e4cdf947fab9e0882385d43324":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"044dfd985840441f9f05bdfb34caba72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a4ab90db32454628a2ebc7985b2e159c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5559215bf2964713b170fd61f6397b3a"}},"340a4815fb774e9681e4f2ac809f00b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7800b9797854406882f9324daee3172","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 234kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5eac8696d0ac4de1a88fca30f1fe6af7"}},"a4ab90db32454628a2ebc7985b2e159c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5559215bf2964713b170fd61f6397b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7800b9797854406882f9324daee3172":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5eac8696d0ac4de1a88fca30f1fe6af7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4a00ed988e54607ba3260161150e285":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b3cb8d4af896406685dd20da44857841","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc0ed90daae4480b9f9f6edd084b0a34","IPY_MODEL_bed4f3b08c1146129e019dc25944fa61"]}},"b3cb8d4af896406685dd20da44857841":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc0ed90daae4480b9f9f6edd084b0a34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_286399a031b646a1b23d5fd26052835a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32536dbe4ee943468018d6dae733061c"}},"bed4f3b08c1146129e019dc25944fa61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_653da163d6844971a197901e2e764951","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 766kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_224d41d9978947d5b13d0bbfb57c978d"}},"286399a031b646a1b23d5fd26052835a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32536dbe4ee943468018d6dae733061c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"653da163d6844971a197901e2e764951":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"224d41d9978947d5b13d0bbfb57c978d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b345006ae706410291891e5e966f3551":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5be7eced1b244895ab0e2d1e0750b371","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c265019ba8a4e129ccb48337081e0a0","IPY_MODEL_0dfef3ecbc334bf3968534083741e4da"]}},"5be7eced1b244895ab0e2d1e0750b371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c265019ba8a4e129ccb48337081e0a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_369c423a482b466c99118887e58693a4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8f2a0e623df4fd59e795b37ae33b719"}},"0dfef3ecbc334bf3968534083741e4da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_54c47f9012c84fec8fef18922e843bba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [01:21&lt;00:00, 2.92s/B]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e39f942f784c4e059d31f351db021e4f"}},"369c423a482b466c99118887e58693a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8f2a0e623df4fd59e795b37ae33b719":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54c47f9012c84fec8fef18922e843bba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e39f942f784c4e059d31f351db021e4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3667a9676dbf4ca29281f6318d876f9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_057eb31c352645df99ddb7633197682f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9167b4c3b85541f28facbf0a9ee5d2d6","IPY_MODEL_36f0133e1dea49758d1c0804ad3f424f"]}},"057eb31c352645df99ddb7633197682f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9167b4c3b85541f28facbf0a9ee5d2d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5631f44d83224e0c86feb55ea801094f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c607c3f8f03c4613b44b458c1044947c"}},"36f0133e1dea49758d1c0804ad3f424f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4bf7520b5544bdc9bdeec5d382c9628","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:13&lt;00:00, 41.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5a6edb24773472d88213125c92569f0"}},"5631f44d83224e0c86feb55ea801094f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c607c3f8f03c4613b44b458c1044947c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4bf7520b5544bdc9bdeec5d382c9628":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5a6edb24773472d88213125c92569f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"8i2KYNS6zQBg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616114151914,"user_tz":240,"elapsed":13153,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"8b09b1dc-95d1-4d74-d5c3-df953e28d2e1"},"source":["# !pip install transformers -q\n","# !pip install sentencepiece -q"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 2.0MB 6.6MB/s \n","\u001b[K     |████████████████████████████████| 3.2MB 23.0MB/s \n","\u001b[K     |████████████████████████████████| 890kB 38.4MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 1.2MB 5.3MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"7O-IQCFjyBoj","executionInfo":{"status":"ok","timestamp":1616114372292,"user_tz":240,"elapsed":6732,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["import os\n","import json\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import transformers\n","from transformers import TFAutoModel, AutoTokenizer\n","from tqdm.notebook import tqdm\n","from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n","\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","\n","SEED = 42"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4daLVmhAzMWt","executionInfo":{"status":"ok","timestamp":1616114384241,"user_tz":240,"elapsed":16990,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"98eb0c4f-85f5-4722-a7ec-d64a847ac56b"},"source":["tf.get_logger().setLevel('ERROR')\n","os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n","\n","if os.environ['COLAB_TPU_ADDR']:\n","  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","  tf.config.experimental_connect_to_cluster(cluster_resolver)\n","  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n","  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n","  print('Using TPU')\n","elif tf.test.is_gpu_available():\n","  strategy = tf.distribute.MirroredStrategy()\n","  print('Using GPU')\n","else:\n","  raise ValueError('Running on CPU is not recomended.')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"],"name":"stderr"},{"output_type":"stream","text":["Using TPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t0T-SZW9vxFz","executionInfo":{"status":"ok","timestamp":1616114384436,"user_tz":240,"elapsed":182,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["AUTO = tf.data.experimental.AUTOTUNE\n","\n","# Configuration\n","EPOCHS = 6\n","bsize = 32\n","BATCH_SIZE = bsize * strategy.num_replicas_in_sync\n","MAX_LEN = 256 # 512"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-x6Eg2lWvPvb"},"source":["# def init(n, model):\n","#   df = pd.read_pickle('wsb_no_topics.pkl')\n","\n","#   with open(f'wsb_topics_{n}.json', 'r') as fp:\n","#     topics = json.load(fp)\n","\n","#   df[\"topic\"] = -1\n","\n","#   for i in range(0, len(topics)):\n","#       df.loc[topics[str(i)], \"topic\"] = i\n","\n","#   n_classes = len(topics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3w-C2efyBon"},"source":["# df = pd.read_pickle('wsb_no_topics.pkl')\n","\n","# with open(f'wsb_topics_{n}.json', 'r') as fp:\n","#   topics = json.load(fp)\n","\n","# df[\"topic\"] = -1\n","\n","# for i in range(0, len(topics)):\n","#     df.loc[topics[str(i)], \"topic\"] = i\n","\n","# n_classes = len(topics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qT07g1zYyBom"},"source":["# AUTO = tf.data.experimental.AUTOTUNE\n","\n","# # Configuration\n","# EPOCHS = 6\n","# bsize = 32\n","# BATCH_SIZE = bsize * strategy.num_replicas_in_sync\n","# MAX_LEN = 256 # 512\n","# MODEL = my_models[3]\n","\n","# print('Selected model: ', MODEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Kd088suyBoo"},"source":["# X = df.selftext.values\n","# y = df.topic.values\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df.topic, test_size=0.2, random_state=SEED)\n","# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRmYt242yBol","executionInfo":{"status":"ok","timestamp":1616114384514,"user_tz":240,"elapsed":257,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["def regular_encode(texts, tokenizer, maxlen=MAX_LEN):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts,\n","        add_special_tokens=True,\n","        truncation=True,\n","        padding='max_length',\n","        return_attention_mask=False, \n","        return_token_type_ids=False,\n","        max_length=maxlen\n","    )\n","    \n","    return np.array(enc_di['input_ids'])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtsKu_RrEcXi","executionInfo":{"status":"ok","timestamp":1616114384514,"user_tz":240,"elapsed":255,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["def build_model(transformer, n_classes, loss='sparse_categorical_crossentropy', max_len=MAX_LEN):\n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    x = tf.keras.layers.Dropout(0.3)(cls_token)\n","    out = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n","    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n","    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss=loss, metrics=['accuracy'])\n","    return model"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"62sD6lEitPua","executionInfo":{"status":"ok","timestamp":1616114384515,"user_tz":240,"elapsed":253,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["def create_datasets(X_train, X_val, X_test, y_train, y_val, y_test, MODEL):\n","  tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)\n","\n","  x_train = regular_encode(X_train.tolist(), tokenizer, maxlen=MAX_LEN)\n","  x_valid = regular_encode(X_val.tolist(), tokenizer, maxlen=MAX_LEN)\n","  x_test = regular_encode(X_test.tolist(), tokenizer, maxlen=MAX_LEN)\n","  y_train = y_train.tolist()\n","  y_valid = y_val.tolist()\n","  y_test = y_test.tolist()\n","\n","\n","  train_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((x_train, y_train))\n","      .repeat()\n","      .shuffle(2048, seed=SEED)\n","      .batch(BATCH_SIZE)\n","      .prefetch(AUTO)\n","  )\n","\n","  valid_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((x_valid, y_valid))\n","      .batch(BATCH_SIZE)\n","      .cache()\n","      .prefetch(AUTO)\n","  )\n","\n","  test_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices(x_test)\n","      .batch(BATCH_SIZE)\n","  )\n","\n","  n_steps = n_steps = x_train.shape[0] // BATCH_SIZE\n","\n","  return train_dataset, valid_dataset, test_dataset, n_steps"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"wAtv0C8Kt4sM","executionInfo":{"status":"ok","timestamp":1616115238951,"user_tz":240,"elapsed":170,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["def main(n):\n","  df = pd.read_pickle('relationships_no_labels.pkl')\n","\n","  with open(f'relationships_topics_{n}.json', 'r') as fp:\n","    topics = json.load(fp)\n","\n","  df[\"topic\"] = -1\n","\n","  for i in range(0, len(topics)):\n","      df.loc[topics[str(i)], \"topic\"] = i\n","\n","  n_classes = len(topics)\n","\n","  X = df.selftext.values\n","  y = df.topic.values\n","\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df.topic, test_size=0.2, random_state=SEED)\n","  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=SEED)\n","\n","  train_dataset, valid_dataset, test_dataset, n_steps = create_datasets(X_train, X_val, X_test, y_train, y_val, y_test, MODEL)\n","\n","  with strategy.scope():\n","    transformer_layer = transformers.TFAutoModel.from_pretrained(MODEL)\n","    model = build_model(transformer_layer, n_classes, max_len=MAX_LEN)\n","\n","  train_history = model.fit(\n","      train_dataset,\n","      steps_per_epoch=n_steps,\n","      validation_data=valid_dataset,\n","      epochs=EPOCHS\n","  )\n","\n","  y_pred = model.predict(test_dataset, verbose=1)\n","\n","  predictions = [np.argmax(p) for p in y_pred]\n","  print(f'model: {MODEL}, epochs: {EPOCHS}, sample_len: {MAX_LEN}, batch_size: {bsize}')\n","  print(classification_report(y_test, predictions))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BdyYuEAduH-","executionInfo":{"status":"ok","timestamp":1616114584274,"user_tz":240,"elapsed":120,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}}},"source":["my_models = ['bert-base-uncased', 'roberta-base', 'jplu/tf-xlm-roberta-base',\n","             'distilbert-base-uncased-finetuned-sst-2-english']\n","\n","MODEL = my_models[0]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["edab0aabc99c493aae14171a5eabb764","422e749140fe49f4a8f40bf4f32a4f7a","022b6e37c2924ae293e8926159e9f20b","d1161f2d91914d5ea5f52f96abd1ce15","aba4ad62a7894eaaa2d9b576077f5ab6","7ee6c2b6347b463fb19f595b012dc5d8","5e306762228d4c2f931afc7d621ee368","64e1b4a8a1fc4e7ca5ec84f76daaa70b","2aaf7773e0a84ce6ab12e8828e826838","8e8511e4cdf947fab9e0882385d43324","044dfd985840441f9f05bdfb34caba72","340a4815fb774e9681e4f2ac809f00b1","a4ab90db32454628a2ebc7985b2e159c","5559215bf2964713b170fd61f6397b3a","d7800b9797854406882f9324daee3172","5eac8696d0ac4de1a88fca30f1fe6af7","e4a00ed988e54607ba3260161150e285","b3cb8d4af896406685dd20da44857841","dc0ed90daae4480b9f9f6edd084b0a34","bed4f3b08c1146129e019dc25944fa61","286399a031b646a1b23d5fd26052835a","32536dbe4ee943468018d6dae733061c","653da163d6844971a197901e2e764951","224d41d9978947d5b13d0bbfb57c978d","b345006ae706410291891e5e966f3551","5be7eced1b244895ab0e2d1e0750b371","6c265019ba8a4e129ccb48337081e0a0","0dfef3ecbc334bf3968534083741e4da","369c423a482b466c99118887e58693a4","b8f2a0e623df4fd59e795b37ae33b719","54c47f9012c84fec8fef18922e843bba","e39f942f784c4e059d31f351db021e4f","3667a9676dbf4ca29281f6318d876f9b","057eb31c352645df99ddb7633197682f","9167b4c3b85541f28facbf0a9ee5d2d6","36f0133e1dea49758d1c0804ad3f424f","5631f44d83224e0c86feb55ea801094f","c607c3f8f03c4613b44b458c1044947c","a4bf7520b5544bdc9bdeec5d382c9628","f5a6edb24773472d88213125c92569f0"]},"id":"cG-TN77g26vj","executionInfo":{"status":"ok","timestamp":1616120439497,"user_tz":240,"elapsed":5196795,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"c1e8dae9-8920-417f-86a6-2b334863af8f"},"source":["main(5)\n","\n","main(10)\n","\n","main(15)\n","\n","main(20)\n","\n","main(25)\n","\n","main(30)"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"edab0aabc99c493aae14171a5eabb764","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2aaf7773e0a84ce6ab12e8828e826838","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4a00ed988e54607ba3260161150e285","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b345006ae706410291891e5e966f3551","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3667a9676dbf4ca29281f6318d876f9b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 181s 461ms/step - loss: 1.1010 - accuracy: 0.5427 - val_loss: 0.6095 - val_accuracy: 0.7557\n","Epoch 2/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.6414 - accuracy: 0.7500 - val_loss: 0.5794 - val_accuracy: 0.7682\n","Epoch 3/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.5770 - accuracy: 0.7736 - val_loss: 0.5689 - val_accuracy: 0.7729\n","Epoch 4/6\n","232/232 [==============================] - 93s 402ms/step - loss: 0.5348 - accuracy: 0.7922 - val_loss: 0.5706 - val_accuracy: 0.7744\n","Epoch 5/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.4940 - accuracy: 0.8082 - val_loss: 0.5814 - val_accuracy: 0.7737\n","Epoch 6/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.4574 - accuracy: 0.8237 - val_loss: 0.6137 - val_accuracy: 0.7710\n","73/73 [==============================] - 23s 262ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.80      0.78      4458\n","           1       0.68      0.77      0.72      3702\n","           2       0.78      0.72      0.75      1657\n","           3       0.76      0.79      0.78      2634\n","           4       0.86      0.77      0.81      6155\n","\n","    accuracy                           0.78     18606\n","   macro avg       0.77      0.77      0.77     18606\n","weighted avg       0.78      0.78      0.78     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 184s 461ms/step - loss: 1.7297 - accuracy: 0.3864 - val_loss: 0.9616 - val_accuracy: 0.6540\n","Epoch 2/6\n","232/232 [==============================] - 94s 404ms/step - loss: 0.9686 - accuracy: 0.6518 - val_loss: 0.9002 - val_accuracy: 0.6757\n","Epoch 3/6\n","232/232 [==============================] - 94s 406ms/step - loss: 0.8666 - accuracy: 0.6873 - val_loss: 0.8836 - val_accuracy: 0.6845\n","Epoch 4/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.8089 - accuracy: 0.7088 - val_loss: 0.8382 - val_accuracy: 0.6969\n","Epoch 5/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.7688 - accuracy: 0.7225 - val_loss: 0.8582 - val_accuracy: 0.7007\n","Epoch 6/6\n","232/232 [==============================] - 93s 403ms/step - loss: 0.7108 - accuracy: 0.7438 - val_loss: 0.8757 - val_accuracy: 0.6922\n","73/73 [==============================] - 23s 262ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.76      0.74      3072\n","           1       0.71      0.78      0.74      3882\n","           2       0.59      0.61      0.60       475\n","           3       0.70      0.73      0.72       897\n","           4       0.79      0.61      0.69      3784\n","           5       0.67      0.75      0.71      1859\n","           6       0.68      0.63      0.65      1329\n","           7       0.50      0.47      0.48       723\n","           8       0.59      0.74      0.66       724\n","           9       0.67      0.66      0.66      1861\n","\n","    accuracy                           0.70     18606\n","   macro avg       0.66      0.67      0.66     18606\n","weighted avg       0.70      0.70      0.69     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 188s 463ms/step - loss: 2.1300 - accuracy: 0.3007 - val_loss: 1.1891 - val_accuracy: 0.5884\n","Epoch 2/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.2036 - accuracy: 0.5932 - val_loss: 1.1221 - val_accuracy: 0.6150\n","Epoch 3/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.0936 - accuracy: 0.6284 - val_loss: 1.1041 - val_accuracy: 0.6257\n","Epoch 4/6\n","232/232 [==============================] - 94s 404ms/step - loss: 1.0165 - accuracy: 0.6505 - val_loss: 1.0391 - val_accuracy: 0.6396\n","Epoch 5/6\n","232/232 [==============================] - 94s 406ms/step - loss: 0.9480 - accuracy: 0.6729 - val_loss: 1.0585 - val_accuracy: 0.6410\n","Epoch 6/6\n","232/232 [==============================] - 94s 405ms/step - loss: 0.8864 - accuracy: 0.6929 - val_loss: 1.0840 - val_accuracy: 0.6393\n","73/73 [==============================] - 24s 265ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.61      0.62      1930\n","           1       0.58      0.79      0.67      2295\n","           2       0.57      0.54      0.55       287\n","           3       0.60      0.71      0.65       736\n","           4       0.69      0.55      0.61      2555\n","           5       0.67      0.62      0.65       906\n","           6       0.64      0.65      0.64      1083\n","           7       0.55      0.31      0.40       436\n","           8       0.64      0.64      0.64       669\n","           9       0.69      0.45      0.55       696\n","          10       0.77      0.66      0.71      1856\n","          11       0.65      0.71      0.68      2097\n","          12       0.65      0.74      0.69       257\n","          13       0.59      0.68      0.63      1958\n","          14       0.77      0.64      0.70       845\n","\n","    accuracy                           0.64     18606\n","   macro avg       0.65      0.62      0.63     18606\n","weighted avg       0.65      0.64      0.64     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 184s 463ms/step - loss: 2.2876 - accuracy: 0.3058 - val_loss: 1.2994 - val_accuracy: 0.5699\n","Epoch 2/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.3603 - accuracy: 0.5534 - val_loss: 1.1781 - val_accuracy: 0.6056\n","Epoch 3/6\n","232/232 [==============================] - 94s 405ms/step - loss: 1.2311 - accuracy: 0.5917 - val_loss: 1.1520 - val_accuracy: 0.6146\n","Epoch 4/6\n","232/232 [==============================] - 94s 404ms/step - loss: 1.1510 - accuracy: 0.6149 - val_loss: 1.1449 - val_accuracy: 0.6199\n","Epoch 5/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.0769 - accuracy: 0.6411 - val_loss: 1.1642 - val_accuracy: 0.6202\n","Epoch 6/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.0240 - accuracy: 0.6563 - val_loss: 1.1634 - val_accuracy: 0.6222\n","73/73 [==============================] - 24s 264ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.57      0.46      0.51       976\n","           1       0.59      0.66      0.62      1066\n","           2       0.63      0.42      0.51       171\n","           3       0.64      0.67      0.66       499\n","           4       0.64      0.53      0.58      2156\n","           5       0.63      0.58      0.60      1087\n","           6       0.57      0.74      0.64       954\n","           7       0.52      0.45      0.48       528\n","           8       0.63      0.71      0.66       595\n","           9       0.49      0.48      0.49       503\n","          10       0.64      0.76      0.69       940\n","          11       0.73      0.51      0.60      1758\n","          12       0.73      0.70      0.72       219\n","          13       0.47      0.67      0.55      1261\n","          14       0.73      0.51      0.60       632\n","          15       0.43      0.55      0.48       372\n","          16       0.00      0.00      0.00        14\n","          17       0.61      0.52      0.56       955\n","          18       0.62      0.47      0.54       529\n","          19       0.66      0.76      0.71      3391\n","\n","    accuracy                           0.61     18606\n","   macro avg       0.58      0.56      0.56     18606\n","weighted avg       0.62      0.61      0.61     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 186s 466ms/step - loss: 2.4772 - accuracy: 0.2709 - val_loss: 1.4216 - val_accuracy: 0.5545\n","Epoch 2/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.4706 - accuracy: 0.5391 - val_loss: 1.3186 - val_accuracy: 0.5801\n","Epoch 3/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.3209 - accuracy: 0.5786 - val_loss: 1.2921 - val_accuracy: 0.5856\n","Epoch 4/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.2369 - accuracy: 0.6013 - val_loss: 1.2817 - val_accuracy: 0.5890\n","Epoch 5/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.1565 - accuracy: 0.6265 - val_loss: 1.2640 - val_accuracy: 0.5962\n","Epoch 6/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.0977 - accuracy: 0.6415 - val_loss: 1.2596 - val_accuracy: 0.5981\n","73/73 [==============================] - 23s 265ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.31      0.43       825\n","           1       0.56      0.47      0.51       320\n","           2       0.56      0.40      0.47       155\n","           3       0.57      0.78      0.66       453\n","           4       0.57      0.47      0.52      1735\n","           5       0.49      0.52      0.50       452\n","           6       0.60      0.58      0.59       831\n","           7       0.60      0.38      0.46       183\n","           8       0.61      0.75      0.68       552\n","           9       0.45      0.11      0.18       127\n","          10       0.64      0.58      0.61       778\n","          11       0.67      0.61      0.64      1389\n","          12       0.75      0.57      0.65       153\n","          13       0.41      0.56      0.47       546\n","          14       0.63      0.61      0.62       565\n","          15       0.56      0.42      0.48        85\n","          16       0.00      0.00      0.00         2\n","          17       0.57      0.47      0.51       795\n","          18       0.56      0.46      0.50       389\n","          19       0.66      0.72      0.69      2828\n","          20       0.57      0.72      0.64      1908\n","          21       0.61      0.69      0.64      1342\n","          22       0.65      0.64      0.65       281\n","          23       0.66      0.66      0.66      1176\n","          24       0.49      0.50      0.49       736\n","\n","    accuracy                           0.60     18606\n","   macro avg       0.57      0.52      0.53     18606\n","weighted avg       0.60      0.60      0.59     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/6\n","232/232 [==============================] - 185s 463ms/step - loss: 2.6434 - accuracy: 0.2374 - val_loss: 1.5612 - val_accuracy: 0.5137\n","Epoch 2/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.5955 - accuracy: 0.5086 - val_loss: 1.4643 - val_accuracy: 0.5377\n","Epoch 3/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.4364 - accuracy: 0.5532 - val_loss: 1.3838 - val_accuracy: 0.5590\n","Epoch 4/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.3393 - accuracy: 0.5772 - val_loss: 1.3625 - val_accuracy: 0.5691\n","Epoch 5/6\n","232/232 [==============================] - 93s 403ms/step - loss: 1.2571 - accuracy: 0.6024 - val_loss: 1.3489 - val_accuracy: 0.5721\n","Epoch 6/6\n","232/232 [==============================] - 93s 402ms/step - loss: 1.1809 - accuracy: 0.6236 - val_loss: 1.3673 - val_accuracy: 0.5708\n","73/73 [==============================] - 23s 266ms/step\n","model: bert-base-uncased, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.56      0.36      0.44       639\n","           1       0.49      0.45      0.47       253\n","           2       0.62      0.44      0.52       135\n","           3       0.65      0.70      0.67       559\n","           4       0.51      0.44      0.47      1397\n","           5       0.56      0.53      0.55       347\n","           6       0.63      0.51      0.57       555\n","           7       0.60      0.45      0.52       148\n","           8       0.64      0.66      0.65       460\n","           9       0.32      0.24      0.27       121\n","          10       0.61      0.56      0.59       521\n","          11       0.58      0.63      0.61      1342\n","          12       0.80      0.23      0.36        35\n","          13       0.45      0.53      0.48       510\n","          14       0.68      0.63      0.65       495\n","          15       0.63      0.30      0.41        96\n","          16       0.00      0.00      0.00         1\n","          17       0.50      0.56      0.53       638\n","          18       0.63      0.37      0.46       329\n","          19       0.64      0.64      0.64      1853\n","          20       0.57      0.67      0.62      1526\n","          21       0.60      0.62      0.61      1234\n","          22       0.67      0.70      0.68       308\n","          23       0.55      0.53      0.54       634\n","          24       0.48      0.43      0.46       635\n","          25       0.45      0.40      0.42        52\n","          26       0.40      0.07      0.11        30\n","          27       0.53      0.70      0.61      1862\n","          28       0.59      0.54      0.57      1352\n","          29       0.64      0.58      0.61       539\n","\n","    accuracy                           0.57     18606\n","   macro avg       0.55      0.48      0.50     18606\n","weighted avg       0.58      0.57      0.57     18606\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22Q88NUhEgGi","executionInfo":{"status":"ok","timestamp":1613762821687,"user_tz":300,"elapsed":38546,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"d63d3a5a-44d6-4b47-8ce1-621e651c9884"},"source":["#building the model on tpu\n","with strategy.scope():\n","    transformer_layer = transformers.TFAutoModel.from_pretrained(MODEL)\n","    model = build_model(transformer_layer, max_len=MAX_LEN)\n","    \n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['dropout_19', 'pre_classifier', 'classifier']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_word_ids (InputLayer)  [(None, 256)]             0         \n","_________________________________________________________________\n","tf_distil_bert_model_4 (TFDi TFBaseModelOutput(last_hi 66362880  \n","_________________________________________________________________\n","tf.__operators__.getitem_4 ( (None, 768)               0         \n","_________________________________________________________________\n","dropout_136 (Dropout)        (None, 768)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 5)                 3845      \n","=================================================================\n","Total params: 66,366,725\n","Trainable params: 66,366,725\n","Non-trainable params: 0\n","_________________________________________________________________\n","CPU times: user 5.89 s, sys: 3.42 s, total: 9.32 s\n","Wall time: 22.7 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5TL7tGl6sryb"},"source":["x_train = regular_encode(X_train.tolist(), tokenizer, maxlen=MAX_LEN)\n","x_valid = regular_encode(X_val.tolist(), tokenizer, maxlen=MAX_LEN)\n","x_test = regular_encode(X_test.tolist(), tokenizer, maxlen=MAX_LEN)\n","y_train = y_train.tolist()\n","y_valid = y_val.tolist()\n","y_test = y_test.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"StDVwq_YyBop"},"source":["train_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((x_train, y_train))\n","    .repeat()\n","    .shuffle(2048, seed=SEED)\n","    .batch(BATCH_SIZE)\n","    .prefetch(AUTO)\n",")\n","\n","valid_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((x_valid, y_valid))\n","    .batch(BATCH_SIZE)\n","    .cache()\n","    .prefetch(AUTO)\n",")\n","\n","test_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices(x_test)\n","    .batch(BATCH_SIZE)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqJEMpWOY_Tt"},"source":["tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9e-KIoKzyBoq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613763034111,"user_tz":300,"elapsed":250963,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"920785f3-3455-4787-dbb6-85cb9abfc3a8"},"source":["n_steps = x_train.shape[0] // BATCH_SIZE\n","train_history = model.fit(\n","    train_dataset,\n","    steps_per_epoch=n_steps,\n","    validation_data=valid_dataset,\n","    epochs=EPOCHS\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/6\n","114/114 [==============================] - 86s 320ms/step - loss: 1.4216 - accuracy: 0.3894 - val_loss: 0.8938 - val_accuracy: 0.6513\n","Epoch 2/6\n","114/114 [==============================] - 25s 220ms/step - loss: 0.9207 - accuracy: 0.6417 - val_loss: 0.7187 - val_accuracy: 0.7239\n","Epoch 3/6\n","114/114 [==============================] - 25s 220ms/step - loss: 0.7381 - accuracy: 0.7157 - val_loss: 0.6775 - val_accuracy: 0.7381\n","Epoch 4/6\n","114/114 [==============================] - 25s 220ms/step - loss: 0.6463 - accuracy: 0.7526 - val_loss: 0.6260 - val_accuracy: 0.7573\n","Epoch 5/6\n","114/114 [==============================] - 25s 220ms/step - loss: 0.5661 - accuracy: 0.7863 - val_loss: 0.6143 - val_accuracy: 0.7627\n","Epoch 6/6\n","114/114 [==============================] - 25s 221ms/step - loss: 0.5144 - accuracy: 0.8039 - val_loss: 0.6016 - val_accuracy: 0.7738\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ugp38ny-QS7g","executionInfo":{"status":"ok","timestamp":1613763077487,"user_tz":300,"elapsed":3413,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"e1a3b5f2-8804-406d-ab5a-05a5003302d0"},"source":["y_pred = model.predict(test_dataset, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["36/36 [==============================] - 3s 63ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YwV8sH8rSC-P","executionInfo":{"status":"ok","timestamp":1613763077488,"user_tz":300,"elapsed":876,"user":{"displayName":"Christopher Kolimago","photoUrl":"https://lh6.googleusercontent.com/-22lz20SlO40/AAAAAAAAAAI/AAAAAAAAMMY/oMU3tUveeiw/s64/photo.jpg","userId":"01478407299799936104"}},"outputId":"9fb147df-0db4-4b36-87e0-381e8235a146"},"source":["predictions = [np.argmax(p) for p in y_pred]\n","print(f'model: {MODEL}, epochs: {EPOCHS}, sample_len: {MAX_LEN}, batch_size: {bsize}')\n","print(classification_report(y_test, predictions))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model: distilbert-base-uncased-finetuned-sst-2-english, epochs: 6, sample_len: 256, batch_size: 32\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.67      0.71      1455\n","           1       0.71      0.78      0.74      2331\n","           2       0.82      0.86      0.84      2872\n","           3       0.78      0.66      0.72      1704\n","           4       0.71      0.73      0.72       810\n","\n","    accuracy                           0.76      9172\n","   macro avg       0.75      0.74      0.74      9172\n","weighted avg       0.76      0.76      0.76      9172\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZKP8wATIo3wl"},"source":["# import seaborn as sns\n","# from sklearn.metrics import confusion_matrix\n","# import matplotlib.pyplot as plt\n","\n","# encoded_classes = list(range(20))\n","# test_topics = y_test\n","# pred_topics = predictions = [np.argmax(p) for p in y_pred]\n","# confusion_mat = confusion_matrix(y_true = test_topics, y_pred = pred_topics, labels=list(encoded_classes))\n","# df_cm = pd.DataFrame(confusion_mat, index = list(encoded_classes),columns = list(encoded_classes))\n","# plt.rcParams['figure.figsize'] = (10,10)\n","# sns.heatmap(df_cm)"],"execution_count":null,"outputs":[]}]}